{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15558,"status":"ok","timestamp":1701788918509,"user":{"displayName":"김성호","userId":"00239474051960738712"},"user_tz":-540},"id":"yAKXA7Z7Gwz0","outputId":"4f4df533-1ac3-4944-cde0-d15865835434"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"4IAMDrBMnClu"},"source":["# Import library"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"lrjtVs-oGODv","executionInfo":{"status":"ok","timestamp":1701789037322,"user_tz":-540,"elapsed":923,"user":{"displayName":"김성호","userId":"00239474051960738712"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"UHVW6Ht3nE_L"},"source":["# Part1: goodFeaturesToTrack\n","- Fill the missing part (denoted as ```fill here```) of the code\n","- We provide procedure comments for complete the function"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"AEPUBxp_GPpl","executionInfo":{"status":"ok","timestamp":1701789077447,"user_tz":-540,"elapsed":2,"user":{"displayName":"김성호","userId":"00239474051960738712"}}},"outputs":[],"source":["def goodFeaturesToTrack(image, maxCorners=100, qualityLevel=0.03, blocksize=7):\n","\n","    # Image bluring wih averaging filter\n","    # Only cv2.filter2D is allowed for convolution operation!\n","    image = cv2.filter2D(image, -1, 1 / 6 * np.ones((blocksize, blocksize))/blocksize**2) # \"Empricially\" # np.ones 앞의 분수값을 변경하면 임계치와 같은 역할을 함\n","\n","    # Compute gradients\n","    Ix = cv2.filter2D(image, -1, 1 / 8 * np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])) # sobel filter + normalization\n","    Iy = cv2.filter2D(image, -1, 1 / 8 * np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).T) # sobel filter + normalization\n","\n","    # Compute products of gradients at each pixel\n","    Ixx = Ix**2\n","    Iyy = Iy**2\n","    Ixy = Ix*Iy\n","\n","    # Compute the sums of products of gradients in local windows\n","    window_size = 5\n","    Sxx = cv2.filter2D(Ixx, -1, np.ones((window_size, window_size)))\n","    Syy = cv2.filter2D(Iyy, -1, np.ones((window_size, window_size)))\n","    Sxy = cv2.filter2D(Ixy, -1, np.ones((window_size, window_size)))\n","\n","    # Compute the determinant and trace of the matrix M for each pixel\n","    detM = Sxx * Syy - Sxy**2\n","    traceM = Sxx + Syy\n","\n","    # Compute the Harris response with detM and traceM\n","    harris_response = detM - 0.04 * (traceM**2)\n","\n","    # Threshold the Harris response to find candidate corners\n","    corners = np.argwhere(harris_response > qualityLevel * harris_response.max())\n","\n","    # Sort the corners by Harris response in descending order\n","    sorted_corners = corners[np.argsort(harris_response[corners[:, 0], corners[:, 1]])[::-1]]\n","\n","    # Keep the top 'maxCorners' corners\n","    selected_corners = sorted_corners[:maxCorners]\n","\n","    final_corners = np.array(selected_corners)\n","    final_corners = final_corners.reshape(-1, 1, 2)\n","\n","    return final_corners"]},{"cell_type":"markdown","metadata":{"id":"0gcb42xzntML"},"source":["# Part2: Optical flow with Lukas-Kanade\n","- Fill the missing part (denoted as ```fill here```) of the code\n","- We provide procedure comments for complete the function"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lv7zvb_nG8ql","executionInfo":{"status":"ok","timestamp":1701789077869,"user_tz":-540,"elapsed":1,"user":{"displayName":"김성호","userId":"00239474051960738712"}}},"outputs":[],"source":["def optical_flow(old_frame, new_frame, window_size, min_quality):\n","\n","    feature_list = goodFeaturesToTrack(old_frame, max_corners, min_quality, blocksize)\n","\n","    w = int(window_size/2)\n","\n","    # Normalize\n","    old_frame = old_frame / 255\n","    new_frame = new_frame / 255\n","\n","    # Convolve to get gradients w.r.to X, Y and T dimensions\n","    kernel_x = 1 / 8 * np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])  # Sobel operator\n","    kernel_y = 1 / 8 * np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]).T  # Sobel operator\n","    kernel_t = 1 / 9 * np.ones((3, 3))  # Simple difference\n","\n","    # cv2.filter2D is allowed for convolution!\n","    fx = cv2.filter2D(old_frame, -1, kernel_x) # cv2.filter2D(src, ddepth, kernel)\n","    fy = cv2.filter2D(old_frame, -1, kernel_y)\n","    ft = cv2.filter2D(new_frame, -1, kernel_t) + cv2.filter2D(old_frame, -1, -kernel_t)\n","\n","    u = np.zeros(old_frame.shape)\n","    v = np.zeros(old_frame.shape)\n","\n","    for feature in feature_list:  # for every corner\n","        i, j = feature.ravel()  # get cordinates of the corners (i,j).\n","        i, j = int(i), int(j)  # i,j are floats initially so convert to integer type\n","\n","        I_x = fx[i-w:i+w+1, j-w:j+w+1].flatten() # Get the window around the corner\n","        I_y = fy[i-w:i+w+1, j-w:j+w+1].flatten()\n","        I_t = ft[i-w:i+w+1, j-w:j+w+1].flatten()\n","\n","        b = np.reshape(I_t, (I_t.shape[0], 1))\n","        A = np.vstack((I_x, I_y)).T\n","\n","        U = np.matmul(np.linalg.pinv(A), -b)  # Solving for (u,v) i.e., U\n","\n","        u[i, j] = U[0][0]\n","        v[i, j] = U[1][0]\n","\n","    return (u, v)\n"]},{"cell_type":"markdown","metadata":{"id":"x4N4xHKEHAjA"},"source":["# Main function\n","- If part1 and part2 were filled properly, the 'output.avi' will be generated!\n","- For google colab, as cv2.imshow() is not provided, so please use cv2_imshow (google.colab.patches) instead  "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1cOU-ylO3NuZc0VKlTAY-Gw8cUYRjWYWm"},"id":"APQHNcblG_Jp","outputId":"61e8b837-dac2-4b69-8d32-61d4ac0bc036","executionInfo":{"status":"ok","timestamp":1701789375906,"user_tz":-540,"elapsed":0,"user":{"displayName":"김성호","userId":"00239474051960738712"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["cap = cv2.VideoCapture('/content/drive/MyDrive/컴퓨터비전개론_ICPBL_PROJECT/slow.mp4')\n","\n","# Take first frame and find corners in it\n","ret, old_frame = cap.read()\n","\n","# Width and height of the file to save\n","width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","\n","# 'output.mp4' will be generated!\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","out = cv2.VideoWriter('/content/drive/MyDrive/컴퓨터비전개론_ICPBL_PROJECT/outputs/output_6.mp4',  fourcc, 30.0, (int(width), int(height)))\n","\n","old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n","\n","# Shi Tomasi parameter\n","max_corners = 100\n","min_quality = 0.3\n","blocksize = 7\n","p0 = goodFeaturesToTrack(old_frame, max_corners, min_quality, blocksize)\n","\n","# Create a mask image for drawing purposes\n","mask = np.zeros_like(old_frame)\n","\n","while(1):\n","    ret, current_frame = cap.read()\n","    if not ret:\n","        break\n","    frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n","\n","    # calculate optical flow\n","    U, V = optical_flow(old_gray, frame_gray, 15, 0.03)\n","\n","    for i in range(current_frame.shape[0]):\n","        for j in range(current_frame.shape[1]):\n","            u, v = U[i][j], V[i][j]\n","\n","            if u and v:\n","                mask = cv2.line(mask, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), 2)\n","                frame = cv2.arrowedLine(current_frame, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), thickness=2)\n","                current_frame = cv2.add(current_frame, mask)\n","\n","    # Display the frame with optical flow vectors\n","    cv2_imshow(current_frame)\n","    out.write(current_frame)\n","    # Break the loop if 'Esc' key is pressed\n","    if cv2.waitKey(30) == 27:\n","        break\n","\n","    # Set the current frame as the previous frame for the next iteration\n","    old_gray = frame_gray\n","\n","# Release the video capture object\n","cap.release()\n","out.release()\n","\n","# Close the plot window when done\n","plt.close()\n","cv2.destroyAllWindows()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}